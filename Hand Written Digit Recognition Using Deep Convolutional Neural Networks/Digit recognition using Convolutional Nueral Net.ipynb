{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit recognition using Convolutional Nueral Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries to install:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries to install:\n",
    "# Lasagne (latest update: https://github.com/Lasagne/Lasagne/archive/master.zip)\n",
    "# Theano (latest update: https://github.com/Theano/Theano/archive/master.zip)\n",
    "# nolearn\n",
    "\n",
    "# if you use Mac, you can easily install everything by running these command in terminal:\n",
    "# pip install nolearn\n",
    "# pip install Lasagne==0.1\n",
    "# pip install -r https://raw.githubusercontent.com/Lasagne/Lasagne/v0.1/requirements.txt\n",
    "# pip install --upgrade https://github.com/Theano/Theano/archive/master.zip\n",
    "# pip install --upgrade https://github.com/Lasagne/Lasagne/archive/master.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required modules (after installing them):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import lasagne\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import visualize\n",
    "\n",
    "#############################################################\n",
    "## import any other modules that you may need (the ddep learning modules have been already imported above)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits including 70,000 images of size 28x28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# downlading the MNIST dataset (it may take afew minutes -- the 55mb MNIST digit dataset will be downloaded)\n",
    "dataset = fetch_mldata(\"MNIST Original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature Table:\n",
    "X = dataset.data.reshape(70000, 1, 28, 28)\n",
    "X = X/255 # move to range of [0,1]\n",
    "\n",
    "# Label:\n",
    "y = dataset.target.astype(\"int32\")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some samples:\n",
    "plt.imshow(X[0,0,:,:],cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()\n",
    "plt.imshow(X[20000,0,:,:],cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Split X and y into testing and traning with 20% as testing and random_state = 0:\n",
    "from sklearn.model_selection import test_train_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, id_df, test_size=0.20, random_state=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the parameters of my Convolutional Neural Network:\n",
    "My ConvNet includes an input layer, one convolutional layers with ReLU for feature extraction, one pooling layers for dimensionality reduction, a fully connected layer (dense layer) for classification, and finally the output layer. It also includes two dropout layers for regularization (cut some of the connections) to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defining the parameters of your Convolutional Neural Network:\n",
    "# My ConvNet includes an input layer, one convolutional layers with ReLU for feature extraction, \n",
    "# one pooling layers for dimensionality reduction, a fully connected layer (dense layer) for classification, \n",
    "# and finally the output layer. It also include two dropout layers for regularization (cut some of the connections) \n",
    "# to avoid overfitting.\n",
    "\n",
    "my_ConvNet = NeuralNet(\n",
    "    layers=[('input', layers.InputLayer),\n",
    "            ('convLayer1', layers.Conv2DLayer),\n",
    "            ('poolingLayer1', layers.MaxPool2DLayer),\n",
    "            ('dropout1', layers.DropoutLayer),\n",
    "            ('dense', layers.DenseLayer),\n",
    "            ('dropout2', layers.DropoutLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "            ],\n",
    "    \n",
    "    # input layer\n",
    "    input_shape=(None, 1, 28, 28),\n",
    "    \n",
    "    # convLayer1\n",
    "    convLayer1_num_filters=16,\n",
    "    convLayer1_filter_size=(5, 5),\n",
    "    convLayer1_nonlinearity = lasagne.nonlinearities.rectify,\n",
    "    convLayer1_W = lasagne.init.GlorotUniform(),  \n",
    "   \n",
    "    # poolingLayer1\n",
    "    poolingLayer1_pool_size=(6, 6),    \n",
    "    \n",
    "    # dropout1\n",
    "    dropout1_p=0.5,    \n",
    "    \n",
    "    # dense\n",
    "    dense_num_units=256,\n",
    "    dense_nonlinearity=lasagne.nonlinearities.rectify,    \n",
    "    \n",
    "    # dropout2\n",
    "    dropout2_p=0.5,    \n",
    "    \n",
    "    # output\n",
    "    output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "    output_num_units=10,\n",
    "    \n",
    "    # optimization method params\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.01,\n",
    "    update_momentum=0.9,\n",
    "    max_epochs=10,\n",
    "    verbose=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainig the ConvNet on the Traning Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training the network\n",
    "### It takes a few minutes!\n",
    "my_ConvNet.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# testing the trained model above, check the accuracy, and print it.\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "my_y_predict = myConvNet(X_test)\n",
    "\n",
    "my_score = accuracy_score(y_test, my_y_predict)\n",
    "\n",
    "print(my_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New ConvNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Now I will design a new ConvNet with the following specifications:\n",
    "# 2 convolutional layers: first one with 32 filters, second one with 16 filter with filter size: (5,5)\n",
    "# 2 pooling layers (one pooling layer after each conv layer) with pool_size: (2,2)\n",
    "# other parameters same as above\n",
    "\n",
    "\n",
    "\n",
    "my_ConvNet2 = NeuralNet(\n",
    "    layers=[('input', layers.InputLayer),\n",
    "            ('convLayer1', layers.Conv2DLayer),\n",
    "            ('convLayer2', layers.Conv2DLayer),\n",
    "            ('poolingLayer1', layers.MaxPool2DLayer),\n",
    "            ('poolingLayer2', layers.MaxPool2DLayer),\n",
    "            ('dropout1', layers.DropoutLayer),\n",
    "            ('dense', layers.DenseLayer),\n",
    "            ('dropout2', layers.DropoutLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "            ],\n",
    "    \n",
    "    # input layer\n",
    "    input_shape=(None, 1, 28, 28),\n",
    "    \n",
    "    # convLayer1\n",
    "    convLayer1_num_filters=32,\n",
    "    convLayer1_filter_size=(5, 5),\n",
    "    convLayer1_nonlinearity = lasagne.nonlinearities.rectify,\n",
    "    convLayer1_W = lasagne.init.GlorotUniform(),  \n",
    "   \n",
    "    # poolingLayer1\n",
    "    poolingLayer1_pool_size=(2, 2),  \n",
    "    \n",
    "    #convLayer2\n",
    "    convLayer2_num_filters=16,\n",
    "    convLayer2_filter_size=(5, 5),\n",
    "    convLayer2_nonlinearity = lasagne.nonlinearities.rectify,\n",
    "    convLayer2_W = lasagne.init.GlorotUniform(),  \n",
    "   \n",
    "    # poolingLayer2\n",
    "    poolingLayer2_pool_size=(2, 2),  \n",
    "    \n",
    "    # dropout1\n",
    "    dropout1_p=0.5,    \n",
    "    \n",
    "    # dense\n",
    "    dense_num_units=256,\n",
    "    dense_nonlinearity=lasagne.nonlinearities.rectify,    \n",
    "    \n",
    "    # dropout2\n",
    "    dropout2_p=0.5,    \n",
    "    \n",
    "    # output\n",
    "    output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "    output_num_units=10,\n",
    "    \n",
    "    # optimization method params\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.01,\n",
    "    update_momentum=0.9,\n",
    "    max_epochs=10,\n",
    "    verbose=1,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# training my new ConvNet.\n",
    "\n",
    "my_ConvNet2.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# testing the trained model above and check the accuracy.\n",
    "my_y_predict2 = my_ConvNet2.predict(X_test)\n",
    "\n",
    "my_score2 = accuracy_score(y_test, my_y_predict2)\n",
    "print(my_score2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
